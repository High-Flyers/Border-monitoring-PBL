{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# How to Train YOLOv5 on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOv5 repository](https://github.com/ultralytics/yolov5) by [Ultralytics](https://www.ultralytics.com/). This notebook shows training on **your own custom objects**. Many thanks to Ultralytics for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv5](https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOv5 on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv5 dependencies\n",
        "* Download custom YOLOv5 object detection data\n",
        "* Write our YOLOv5 Training configuration\n",
        "* Run YOLOv5 training\n",
        "* Evaluate YOLOv5 performance\n",
        "* Visualize YOLOv5 training data\n",
        "* Run YOLOv5 inference on test images\n",
        "* Export saved YOLOv5 weights for future inference\n",
        "\n",
        "\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5uLDH4uzAp",
        "outputId": "e61fa9cd-4bf3-4916-a133-e2ab6f0a89f9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16013, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 16013 (delta 25), reused 23 (delta 13), pack-reused 15967\u001b[K\n",
            "Receiving objects: 100% (16013/16013), 14.60 MiB | 19.07 MiB/s, done.\n",
            "Resolving deltas: 100% (10991/10991), done.\n",
            "/content/yolov5\n",
            "HEAD is now at 064365d Update parse_opt() in export.py to work as in train.py (#10789)\n"
          ]
        }
      ],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard 064365d8683fd002e9ad789c1e91fa3d021b44f0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "d5da10c9-e5cf-48b0-e5b9-68242dd27101",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m184.3/190.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.1.0+cu118 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIhrBF0sPaM"
      },
      "source": [
        "# Download Correctly Formatted Custom Dataset\n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDeebwqS9JbZ"
      },
      "source": [
        "\n",
        "\n",
        "![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "Knxi2ncxWffW",
        "outputId": "0a27693d-72c4-408f-bad0-044f3c52d8b8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m851.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-374ae33bf091>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q roboflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"yolov5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roboflow-yolov5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, model_format, notebook)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monboarding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36mauth\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"onboarding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36mcheck_key\u001b[0;34m(api_key, model, notebook, num_retries)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m\"API Key is of Incorrect Type \\n Expected Type: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: API Key is of Incorrect Type \n Expected Type: <class 'str'>\n Input Type: <class 'NoneType'>"
          ]
        }
      ],
      "source": [
        "#follow the link below to get your download code from from Roboflow\n",
        "!pip install -q roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_PhK1oqwQA",
        "outputId": "862d79aa-ee66-466a-a690-fe50a4454598",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Thermal-detection-of-humans-1 to yolov5pytorch:: 100%|██████████| 2244/2244 [00:00<00:00, 57360.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Thermal-detection-of-humans-1 in yolov5pytorch:: 100%|██████████| 518/518 [00:00<00:00, 11259.70it/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"kY5y1URLQQGG8D9Fp5LP\")\n",
        "project = rf.workspace().project(\"thermal-detection-of-humans\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3DmmGQztJj",
        "outputId": "bcb4e788-a884-47e5-f405-5f7078ba13c9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- Human\n",
            "nc: 1\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: thermal-detection-of-humans\n",
            "  url: https://universe.roboflow.com/pierwszy/thermal-detection-of-humans/dataset/1\n",
            "  version: 1\n",
            "  workspace: pierwszy\n",
            "test: ../test/images\n",
            "train: Thermal-detection-of-humans-1/train/images\n",
            "val: Thermal-detection-of-humans-1/valid/images\n"
          ]
        }
      ],
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n",
        "You do not need to edit these cells, but you may."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dOPn9wjOAwwK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rvt5wilnDyX",
        "outputId": "00c16cdb-33de-43c2-f445-ca8c07737d77",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ],
      "source": [
        "#this is the model configuration we will use for our tutorial\n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t14hhyqdmw6O",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uDxebz13RdRA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "b57a6c8d-fe1b-4939-f038-974a17e17390",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2023-10-23 16:11:14.545796: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-23 16:11:15.429477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5s.yaml, data=/content/yolov5/Thermal-detection-of-humans-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 156 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 26.4MB/s]\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "custom_YOLOv5s summary: 233 layers, 7255094 parameters, 7255094 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 70 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/Thermal-detection-of-humans-1/train/labels... 222 images, 18 backgrounds, 0 corrupt: 100% 222/222 [00:00<00:00, 1599.20it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Thermal-detection-of-humans-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 222/222 [00:00<00:00, 374.88it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/Thermal-detection-of-humans-1/valid/labels... 21 images, 0 backgrounds, 0 corrupt: 100% 21/21 [00:00<00:00, 362.06it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/Thermal-detection-of-humans-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 21/21 [00:00<00:00, 41.76it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.50 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/yolov5s_results/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      1.66G     0.1208    0.02024          0         58        416: 100% 14/14 [00:07<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.06s/it]\n",
            "                   all         21         53   0.000159     0.0189   9.87e-05   9.87e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      1.66G     0.1198    0.01989          0         45        416: 100% 14/14 [00:02<00:00,  6.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.93it/s]\n",
            "                   all         21         53          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      1.66G     0.1159    0.02093          0         40        416: 100% 14/14 [00:01<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.91it/s]\n",
            "                   all         21         53   0.000159     0.0189    8.4e-05    8.4e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      1.66G     0.1169    0.02014          0         49        416: 100% 14/14 [00:02<00:00,  6.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.17it/s]\n",
            "                   all         21         53   0.000317     0.0377   0.000186   1.86e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      1.66G     0.1173    0.02057          0         44        416: 100% 14/14 [00:01<00:00,  7.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.15it/s]\n",
            "                   all         21         53    0.00127      0.151   0.000737   0.000116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      1.66G     0.1134    0.02159          0         53        416: 100% 14/14 [00:03<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.08it/s]\n",
            "                   all         21         53    0.00159      0.189    0.00103   0.000167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      1.66G     0.1097     0.0219          0         59        416: 100% 14/14 [00:02<00:00,  6.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.16it/s]\n",
            "                   all         21         53    0.00302      0.358    0.00219   0.000409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      1.66G     0.1078    0.02126          0         48        416: 100% 14/14 [00:01<00:00,  7.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.72it/s]\n",
            "                   all         21         53    0.00222      0.264     0.0158    0.00288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      1.66G     0.1024    0.02199          0         34        416: 100% 14/14 [00:01<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.39it/s]\n",
            "                   all         21         53    0.00135      0.151   0.000852   0.000273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      1.66G    0.09999    0.02385          0         45        416: 100% 14/14 [00:02<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.01it/s]\n",
            "                   all         21         53          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      1.66G    0.09514    0.02395          0         66        416: 100% 14/14 [00:02<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.45it/s]\n",
            "                   all         21         53    0.00111      0.132   0.000765   0.000116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      1.66G     0.0926    0.02264          0         50        416: 100% 14/14 [00:02<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.74it/s]\n",
            "                   all         21         53    0.00964       0.04    0.00996    0.00274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      1.66G    0.08972    0.02351          0         45        416: 100% 14/14 [00:01<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.80it/s]\n",
            "                   all         21         53       0.11      0.189      0.049     0.0127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      1.66G    0.08314    0.02319          0         59        416: 100% 14/14 [00:01<00:00,  7.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.18it/s]\n",
            "                   all         21         53       0.14      0.283     0.0783     0.0158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      1.66G      0.082    0.02353          0         42        416: 100% 14/14 [00:03<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.74it/s]\n",
            "                   all         21         53      0.167      0.264     0.0913     0.0216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      1.66G    0.07716    0.02346          0         58        416: 100% 14/14 [00:01<00:00,  7.10it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.81it/s]\n",
            "                   all         21         53      0.173      0.226      0.168     0.0243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      1.66G    0.07634    0.02226          0         32        416: 100% 14/14 [00:01<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.68it/s]\n",
            "                   all         21         53      0.182      0.189     0.0901      0.026\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      1.66G     0.0712    0.02239          0         38        416: 100% 14/14 [00:01<00:00,  7.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.58it/s]\n",
            "                   all         21         53      0.156      0.283      0.099     0.0267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      1.66G    0.07442    0.02283          0         47        416: 100% 14/14 [00:02<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "                   all         21         53       0.41      0.509      0.318     0.0898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      1.66G    0.06875    0.02225          0         62        416: 100% 14/14 [00:02<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.62it/s]\n",
            "                   all         21         53      0.312      0.321      0.205     0.0554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      1.66G    0.06937    0.01997          0         53        416: 100% 14/14 [00:01<00:00,  7.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.09it/s]\n",
            "                   all         21         53      0.365      0.377      0.267     0.0749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      1.66G    0.06826    0.02064          0         49        416: 100% 14/14 [00:01<00:00,  7.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.63it/s]\n",
            "                   all         21         53    0.00605      0.189    0.00251    0.00048\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      1.66G    0.06622    0.01993          0         43        416: 100% 14/14 [00:01<00:00,  7.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.26it/s]\n",
            "                   all         21         53      0.395      0.472      0.347       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      1.66G    0.06312    0.01994          0         45        416: 100% 14/14 [00:02<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.70it/s]\n",
            "                   all         21         53      0.505      0.396       0.41       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      1.66G    0.06362    0.01918          0         46        416: 100% 14/14 [00:02<00:00,  5.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.48it/s]\n",
            "                   all         21         53      0.344      0.585      0.355      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      1.66G    0.06288    0.01995          0         54        416: 100% 14/14 [00:02<00:00,  6.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.24it/s]\n",
            "                   all         21         53      0.612      0.528      0.547      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      1.66G    0.06241    0.01846          0         65        416: 100% 14/14 [00:01<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.85it/s]\n",
            "                   all         21         53      0.729      0.661       0.73      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      1.66G    0.06107    0.01972          0         48        416: 100% 14/14 [00:01<00:00,  7.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.81it/s]\n",
            "                   all         21         53      0.704      0.628      0.695      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      1.66G    0.06142     0.0179          0         53        416: 100% 14/14 [00:03<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.06it/s]\n",
            "                   all         21         53      0.687      0.455      0.518      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      1.66G    0.06271    0.01822          0         57        416: 100% 14/14 [00:01<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.73it/s]\n",
            "                   all         21         53      0.465      0.283      0.286      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      1.66G    0.05756    0.01929          0         38        416: 100% 14/14 [00:01<00:00,  7.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n",
            "                   all         21         53      0.668      0.472      0.474      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      1.66G    0.05697    0.01615          0         46        416: 100% 14/14 [00:01<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.02it/s]\n",
            "                   all         21         53      0.791      0.501      0.664      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      1.66G    0.05991    0.01806          0         52        416: 100% 14/14 [00:01<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.91it/s]\n",
            "                   all         21         53      0.774      0.566      0.614      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      1.66G    0.05707    0.01834          0         40        416: 100% 14/14 [00:03<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.71it/s]\n",
            "                   all         21         53      0.847      0.698      0.768      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      1.66G     0.0541    0.01641          0         32        416: 100% 14/14 [00:01<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.63it/s]\n",
            "                   all         21         53      0.684      0.531      0.582      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      1.66G    0.05708    0.01609          0         67        416: 100% 14/14 [00:01<00:00,  7.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.29it/s]\n",
            "                   all         21         53      0.835      0.571      0.679      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      1.66G    0.05729    0.01641          0         49        416: 100% 14/14 [00:01<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.38it/s]\n",
            "                   all         21         53      0.754      0.695      0.737      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      1.66G    0.05248    0.01736          0         49        416: 100% 14/14 [00:01<00:00,  7.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.05it/s]\n",
            "                   all         21         53      0.824      0.618      0.729      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      1.66G    0.05521    0.01525          0         36        416: 100% 14/14 [00:03<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.88it/s]\n",
            "                   all         21         53      0.792      0.718      0.805      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      1.66G    0.05356    0.01581          0         49        416: 100% 14/14 [00:02<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.07it/s]\n",
            "                   all         21         53       0.85      0.717       0.83      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      1.66G    0.05382    0.01588          0         31        416: 100% 14/14 [00:01<00:00,  7.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.50it/s]\n",
            "                   all         21         53      0.841      0.717      0.807      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      1.66G    0.05139    0.01563          0         38        416: 100% 14/14 [00:01<00:00,  7.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.01it/s]\n",
            "                   all         21         53      0.734      0.849       0.84      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      1.66G     0.0543    0.01501          0         37        416: 100% 14/14 [00:01<00:00,  7.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.51it/s]\n",
            "                   all         21         53      0.685       0.78        0.8       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      1.66G    0.05038    0.01637          0         65        416: 100% 14/14 [00:03<00:00,  4.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.95it/s]\n",
            "                   all         21         53       0.82      0.868      0.867      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      1.66G    0.05243    0.01556          0         43        416: 100% 14/14 [00:01<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.19it/s]\n",
            "                   all         21         53      0.798      0.849       0.85      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      1.66G     0.0511    0.01486          0         37        416: 100% 14/14 [00:01<00:00,  7.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.03it/s]\n",
            "                   all         21         53        0.8       0.83      0.826      0.385\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      1.66G    0.05216    0.01461          0         51        416: 100% 14/14 [00:01<00:00,  7.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.66it/s]\n",
            "                   all         21         53      0.814      0.828      0.855      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      1.66G    0.05036    0.01588          0         39        416: 100% 14/14 [00:02<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.75it/s]\n",
            "                   all         21         53      0.816      0.753      0.864      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      1.66G    0.05168    0.01569          0         52        416: 100% 14/14 [00:02<00:00,  4.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.50it/s]\n",
            "                   all         21         53      0.826      0.811      0.849      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      1.66G    0.04814    0.01547          0         56        416: 100% 14/14 [00:02<00:00,  6.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.72it/s]\n",
            "                   all         21         53      0.863      0.792      0.877        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      1.66G       0.05    0.01646          0         48        416: 100% 14/14 [00:01<00:00,  7.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.29it/s]\n",
            "                   all         21         53      0.927      0.715      0.863      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      1.66G     0.0498    0.01443          0         43        416: 100% 14/14 [00:01<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.60it/s]\n",
            "                   all         21         53      0.808      0.849      0.868      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      1.66G    0.04838    0.01399          0         47        416: 100% 14/14 [00:02<00:00,  5.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.56it/s]\n",
            "                   all         21         53      0.838       0.83      0.859      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      1.66G    0.04876    0.01482          0         53        416: 100% 14/14 [00:02<00:00,  5.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.71it/s]\n",
            "                   all         21         53      0.903      0.736      0.837      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      1.66G    0.04751    0.01556          0         44        416: 100% 14/14 [00:01<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.89it/s]\n",
            "                   all         21         53      0.928      0.732      0.861      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      1.66G    0.04977    0.01473          0         48        416: 100% 14/14 [00:01<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.92it/s]\n",
            "                   all         21         53      0.852      0.868      0.864       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      1.66G    0.04799    0.01418          0         54        416: 100% 14/14 [00:01<00:00,  7.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.55it/s]\n",
            "                   all         21         53      0.803       0.83      0.871       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      1.66G    0.04755    0.01295          0         39        416: 100% 14/14 [00:02<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.07it/s]\n",
            "                   all         21         53      0.834      0.849       0.87       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      1.66G     0.0469    0.01407          0         42        416: 100% 14/14 [00:02<00:00,  6.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.86it/s]\n",
            "                   all         21         53      0.806      0.792      0.846      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      1.66G     0.0464    0.01488          0         55        416: 100% 14/14 [00:01<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.92it/s]\n",
            "                   all         21         53      0.842      0.806      0.865      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      1.66G    0.04708    0.01418          0         48        416: 100% 14/14 [00:01<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.81it/s]\n",
            "                   all         21         53      0.885      0.755      0.869       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      1.66G    0.04727    0.01364          0         52        416: 100% 14/14 [00:01<00:00,  7.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.48it/s]\n",
            "                   all         21         53      0.825      0.803      0.857       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      1.66G    0.04574    0.01487          0         52        416: 100% 14/14 [00:02<00:00,  5.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.26it/s]\n",
            "                   all         21         53      0.826      0.805      0.843      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      1.66G    0.04338    0.01425          0         51        416: 100% 14/14 [00:02<00:00,  6.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.01it/s]\n",
            "                   all         21         53      0.864      0.755      0.812      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      1.66G    0.04689    0.01391          0         46        416: 100% 14/14 [00:01<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.69it/s]\n",
            "                   all         21         53      0.783      0.811      0.827      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      1.66G    0.04389    0.01418          0         59        416: 100% 14/14 [00:01<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.96it/s]\n",
            "                   all         21         53      0.837      0.736      0.852      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      1.66G     0.0459    0.01322          0         36        416: 100% 14/14 [00:01<00:00,  7.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.64it/s]\n",
            "                   all         21         53      0.771      0.868      0.872      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      1.66G    0.04572    0.01399          0         56        416: 100% 14/14 [00:02<00:00,  5.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.41it/s]\n",
            "                   all         21         53      0.837      0.811      0.862      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      1.66G    0.04386    0.01395          0         44        416: 100% 14/14 [00:01<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.51it/s]\n",
            "                   all         21         53      0.848      0.811      0.861      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      1.66G    0.04401    0.01323          0         53        416: 100% 14/14 [00:01<00:00,  7.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.37it/s]\n",
            "                   all         21         53      0.828       0.83      0.879      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      1.66G    0.04253    0.01412          0         35        416: 100% 14/14 [00:01<00:00,  7.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n",
            "                   all         21         53      0.926      0.711      0.843      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      1.66G    0.04393    0.01425          0         41        416: 100% 14/14 [00:01<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.35it/s]\n",
            "                   all         21         53      0.778      0.792      0.821       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      1.66G    0.04666    0.01316          0         36        416: 100% 14/14 [00:03<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.23it/s]\n",
            "                   all         21         53      0.844      0.816      0.881      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      1.66G    0.04393    0.01306          0         48        416: 100% 14/14 [00:01<00:00,  7.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.98it/s]\n",
            "                   all         21         53       0.94      0.717      0.852       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      1.66G    0.04357    0.01334          0         45        416: 100% 14/14 [00:01<00:00,  7.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.96it/s]\n",
            "                   all         21         53      0.943      0.736      0.867      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      1.66G    0.04317    0.01249          0         64        416: 100% 14/14 [00:01<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.46it/s]\n",
            "                   all         21         53      0.942      0.736      0.871      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      1.66G    0.04099    0.01364          0         43        416: 100% 14/14 [00:01<00:00,  7.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.74it/s]\n",
            "                   all         21         53      0.965      0.736      0.864      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      1.66G    0.04109    0.01339          0         46        416: 100% 14/14 [00:03<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.77it/s]\n",
            "                   all         21         53      0.903      0.774      0.867      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      1.66G    0.03954    0.01254          0         32        416: 100% 14/14 [00:01<00:00,  7.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.16it/s]\n",
            "                   all         21         53      0.952      0.755      0.873      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      1.66G    0.03986    0.01267          0         49        416: 100% 14/14 [00:01<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.60it/s]\n",
            "                   all         21         53      0.946      0.774      0.875      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      1.66G    0.04058    0.01307          0         42        416: 100% 14/14 [00:01<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.81it/s]\n",
            "                   all         21         53      0.915      0.774      0.868      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      1.66G    0.04145    0.01268          0         53        416: 100% 14/14 [00:03<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.40it/s]\n",
            "                   all         21         53      0.874      0.792       0.87      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      1.66G    0.03887    0.01292          0         32        416: 100% 14/14 [00:02<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.97it/s]\n",
            "                   all         21         53      0.865      0.774      0.879      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      1.66G    0.04095    0.01319          0         58        416: 100% 14/14 [00:01<00:00,  7.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.44it/s]\n",
            "                   all         21         53       0.83      0.828      0.894      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      1.66G    0.03973     0.0128          0         59        416: 100% 14/14 [00:01<00:00,  7.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.67it/s]\n",
            "                   all         21         53      0.957      0.736      0.883       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      1.66G    0.04059    0.01314          0         68        416: 100% 14/14 [00:02<00:00,  6.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.42it/s]\n",
            "                   all         21         53      0.831      0.811      0.875      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      1.66G    0.04001    0.01254          0         48        416: 100% 14/14 [00:03<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.93it/s]\n",
            "                   all         21         53      0.845       0.83      0.878      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      1.66G    0.04123    0.01218          0         52        416: 100% 14/14 [00:01<00:00,  7.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.82it/s]\n",
            "                   all         21         53       0.82      0.792      0.866      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      1.66G    0.03916      0.013          0         51        416: 100% 14/14 [00:01<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.98it/s]\n",
            "                   all         21         53      0.774      0.841      0.868      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      1.66G    0.04223    0.01288          0         51        416: 100% 14/14 [00:01<00:00,  7.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.14it/s]\n",
            "                   all         21         53      0.915      0.736      0.869      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      1.66G     0.0396     0.0127          0         42        416: 100% 14/14 [00:02<00:00,  5.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.12it/s]\n",
            "                   all         21         53      0.912      0.778       0.88      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      1.66G    0.04118    0.01249          0         56        416: 100% 14/14 [00:02<00:00,  5.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.13it/s]\n",
            "                   all         21         53      0.916      0.792      0.881      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      1.66G    0.03932    0.01215          0         41        416: 100% 14/14 [00:02<00:00,  6.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.07it/s]\n",
            "                   all         21         53      0.954      0.779      0.888      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      1.66G    0.04037    0.01355          0         63        416: 100% 14/14 [00:02<00:00,  6.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.55it/s]\n",
            "                   all         21         53      0.942      0.792      0.903      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      1.66G    0.03885    0.01242          0         59        416: 100% 14/14 [00:02<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.83it/s]\n",
            "                   all         21         53      0.932      0.776      0.879      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      1.66G    0.03725    0.01297          0         53        416: 100% 14/14 [00:03<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.46it/s]\n",
            "                   all         21         53      0.927      0.792       0.87      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      1.66G    0.03805    0.01206          0         45        416: 100% 14/14 [00:01<00:00,  7.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.27it/s]\n",
            "                   all         21         53      0.928      0.792      0.907      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      1.66G    0.04076    0.01304          0         50        416: 100% 14/14 [00:01<00:00,  7.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.73it/s]\n",
            "                   all         21         53      0.941      0.774      0.893      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      1.66G    0.03924    0.01341          0         59        416: 100% 14/14 [00:01<00:00,  7.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.11it/s]\n",
            "                   all         21         53      0.953      0.772      0.899      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      1.66G     0.0384    0.01285          0         47        416:  71% 10/14 [00:01<00:00,  6.46it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 634, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 528, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 317, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 492, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 251, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "CPU times: user 3.59 s, sys: 375 ms, total: 3.97 s\n",
            "Wall time: 5min 17s\n"
          ]
        }
      ],
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save output model to ONNX"
      ],
      "metadata": {
        "id": "ZVQ7c1-0U7l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx\n",
        "\n",
        "import torch\n",
        "from utils.torch_utils import select_device, smart_inference_mode\n",
        "from models.common import DetectMultiBackend\n",
        "\n",
        "device = select_device(0)\n",
        "model = DetectMultiBackend(\"/content/yolov5/runs/train/yolov5s_results/weights/best.pt\", device=device, dnn=False, fp16=False)\n",
        "x = torch.randn(1, 3, 640, 640, requires_grad=True).to(device)\n",
        "torch.onnx.export(model, x, \"./model.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWx7RixPU6uW",
        "outputId": "9232affa-0bfb-4889-86af-7f774a96d884"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-72-g064365d Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7246518 parameters, 0 gradients\n",
            "Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEFXxQtAXezt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}